{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for generating samples from different series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "def arithmetic_prog(n_terms, a1=1, d=1):\n",
    "    a = []\n",
    "    for i in range(n_terms):\n",
    "        a.append(a1)\n",
    "        a1 += d\n",
    "    return a\n",
    "\n",
    "def geometric_prog(n_terms, a1=1, r=2):\n",
    "    a = []\n",
    "    for i in range(n_terms):\n",
    "        a.append(a1)\n",
    "        a1 *= r\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sequences(n, terms, largest_start):\n",
    "    \"\"\"\n",
    "    Generate random arithmetic sequences\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(n):\n",
    "        a1 = randint(1, largest_start)\n",
    "        d = randint(1, largest_start)\n",
    "        seq = arithmetic_prog(terms, a1, d)\n",
    "        X.append(seq[:-1])\n",
    "        y.append(seq[-1])\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = random_sequences(10, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(X, y):\n",
    "    Xstr = []\n",
    "    for seq in X:\n",
    "        Xstr.append(','.join([str(_) for _ in seq]))\n",
    "    ystr = []\n",
    "    for res in y:\n",
    "        ystr.append(str(res))\n",
    "    return Xstr, ystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = to_str(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_encode(X, y, alphabet):\n",
    "    \"\"\"\n",
    "    Encode sequence string as a list of indices in some alphabet\n",
    "    \"\"\"\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    Xenc = []\n",
    "    for seq in X:\n",
    "        seq_enc = [char_to_int[c] for c in seq]\n",
    "        Xenc.append(seq_enc)\n",
    "    yenc = []\n",
    "    for res in y:\n",
    "        res_enc = [char_to_int[c] for c in res]\n",
    "        yenc.append(res_enc)\n",
    "    return Xenc, yenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = tuple(\" 0123456789,\")\n",
    "X, y = seq_encode(X, y, alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X, maxlen=20, value=0, dtype=np.int16)\n",
    "y = pad_sequences(y, maxlen=4, value=0, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(X, y, maxint):\n",
    "    Xenc = []\n",
    "    for seq in X:\n",
    "        pattern = []\n",
    "        for i in seq:\n",
    "            vec = [0 for _ in range(maxint)]\n",
    "            vec[i] = 1\n",
    "            pattern.append(vec)\n",
    "        Xenc.append(pattern)\n",
    "    yenc = []\n",
    "    for seq in y:\n",
    "        pattern = []\n",
    "        for i in seq:\n",
    "            vec = [0 for _ in range(maxint)]\n",
    "            vec[i] = 1\n",
    "            pattern.append(vec)\n",
    "        yenc.append(pattern)\n",
    "    return Xenc, yenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = one_hot_encode(X, y, len(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert(seq, alphabet):\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    strings = []\n",
    "    for pattern in seq:\n",
    "        s = []\n",
    "        for sym in pattern:\n",
    "            s.append(int_to_char[np.argmax(sym)])\n",
    "        strings.append(''.join(s))\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  50', '7120']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invert(y, alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(n_samples, X_maxlen, y_maxlen, alphabet):\n",
    "    # alphabet should start with padding value\n",
    "    X, y = random_sequences(n_samples, terms=10, largest_start=10)\n",
    "    X, y = to_str(X, y)\n",
    "    X, y = seq_encode(X, y, alphabet)\n",
    "    X = pad_sequences(X, maxlen=X_maxlen, value=0, dtype=np.int16)\n",
    "    y = pad_sequences(y, maxlen=y_maxlen, value=0, dtype=np.int16)\n",
    "    X, y = one_hot_encode(X, y, len(alphabet))\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['      5,8,11,14,17,20,23,26,29']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invert(prep_data(1, 30, 3, alphabet)[0], alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(X_maxlen, y_maxlen, alphabet, batch_size=32):\n",
    "    # alphabet should start with padding value\n",
    "    while True:\n",
    "        X, y = random_sequences(batch_size, terms=10, largest_start=10)\n",
    "        X, y = to_str(X, y)\n",
    "        X, y = seq_encode(X, y, alphabet)\n",
    "        X = pad_sequences(X, maxlen=X_maxlen, value=0, dtype=np.int16)\n",
    "        y = pad_sequences(y, maxlen=y_maxlen, value=0, dtype=np.int16)\n",
    "        X, y = one_hot_encode(X, y, len(alphabet))\n",
    "        yield np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_length, out_length = 30, 3\n",
    "n_chars = len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, TimeDistributed, RepeatVector, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 10)                920       \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 3, 10)             0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 3, 10)             840       \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 3, 12)             132       \n",
      "=================================================================\n",
      "Total params: 1,892\n",
      "Trainable params: 1,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(in_length, n_chars)))\n",
    "model.add(RepeatVector(out_length))\n",
    "model.add(LSTM(10, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_chars, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 1.6910 - acc: 0.3869\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 1.5389 - acc: 0.4014\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 1.4810 - acc: 0.4291\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 1.2436 - acc: 0.5342\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.9721 - acc: 0.6483\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.7733 - acc: 0.7343\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.6036 - acc: 0.8040\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.4670 - acc: 0.8656\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.3547 - acc: 0.9220\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.2617 - acc: 0.9581\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(gen_data(in_length, out_length, alphabet), epochs=10, steps_per_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected= 40, Predicted= 40\n",
      "Expected= 80, Predicted= 80\n",
      "Expected= 16, Predicted= 16\n",
      "Expected= 32, Predicted= 32\n",
      "Expected= 51, Predicted= 52\n"
     ]
    }
   ],
   "source": [
    "## Evaluate:\n",
    "def compare_predictions(model, n_examples):\n",
    "    X, y = prep_data(n_examples, in_length, out_length, alphabet)\n",
    "    res = model.predict(X)\n",
    "    expected = invert(y, alphabet)\n",
    "    predicted = invert(res, alphabet)\n",
    "    for i in range(n_examples):\n",
    "        print(f\"Expected={expected[i]}, Predicted={predicted[i]}\")\n",
    "\n",
    "compare_predictions(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's redefine random_sequences function to produce either arithmetic or geometric progression\n",
    "def random_sequences(n, terms, largest_start):\n",
    "    \"\"\"\n",
    "    Generate random arithmetic sequences\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(n):\n",
    "        a1 = randint(1, largest_start)\n",
    "        d = randint(1, largest_start)\n",
    "        if randint(a=0, b=1) == 1:\n",
    "            seq = arithmetic_prog(terms, a1, d)\n",
    "        else:\n",
    "            seq = geometric_prog(terms, a1, d)\n",
    "        X.append(seq[:-1])\n",
    "        y.append(seq[-1])\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 100)               33900     \n",
      "_________________________________________________________________\n",
      "repeat_vector_4 (RepeatVecto (None, 10, 100)           0         \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 10, 100)           60300     \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 10, 100)           60300     \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 10, 12)            1212      \n",
      "=================================================================\n",
      "Total params: 155,712\n",
      "Trainable params: 155,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# let's also enchance our model architecture\n",
    "in_length, out_length = 100, 10\n",
    "n_chars = len(alphabet)\n",
    "\n",
    "from keras.layers import GRU\n",
    "model_big = Sequential()\n",
    "model_big.add(GRU(100, input_shape=(in_length, n_chars)))\n",
    "model_big.add(RepeatVector(out_length))\n",
    "model_big.add(GRU(100, return_sequences=True))\n",
    "model_big.add(GRU(100, return_sequences=True))\n",
    "model_big.add(TimeDistributed(Dense(n_chars, activation='softmax')))\n",
    "model_big.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_big.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.8434 - acc: 0.6928\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.4224 - acc: 0.8634\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0826 - acc: 0.9902\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0448 - acc: 0.9910\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0084 - acc: 0.9994\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 6.2944e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3.4933e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 1.9028e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1331c1588>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_hist = model_big.fit_generator(gen_data(in_length, out_length, alphabet), epochs=10, steps_per_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=        88, Predicted=        88\n",
      "Expected=7000000000, Predicted=7000000000\n",
      "Expected=        13, Predicted=        13\n",
      "Expected= 242121642, Predicted= 242121642\n",
      "Expected=        65, Predicted=        65\n",
      "Expected=        23, Predicted=        23\n",
      "Expected=        93, Predicted=        93\n",
      "Expected=  10077696, Predicted=  10077696\n",
      "Expected=        71, Predicted=        71\n",
      "Expected=    137781, Predicted=    137781\n"
     ]
    }
   ],
   "source": [
    "compare_predictions(model_big, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using actual data\n",
    "Now we're talking about. Let's replace our `random_sequences` with sampling from the subset of train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"../data/test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222447</th>\n",
       "      <td>10,11,12,13,14,15,16,17,18,19,1011,21,1112,111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126500</th>\n",
       "      <td>1,0,2,0,0,6,0,0,0,21,0,0,0,3,79,0,0,0,0,41,311...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217366</th>\n",
       "      <td>1,2,4,8,15,30,58,114,225,443,871,1715,3375,664...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216</th>\n",
       "      <td>1,2,12,432,31104,6718464,8707129344,2256887925...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65934</th>\n",
       "      <td>1,2,0,3,0,0,1,4,1,0,2,0,0,2,0,5,0,2,0,0,0,4,2,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sequence\n",
       "Id                                                       \n",
       "222447  10,11,12,13,14,15,16,17,18,19,1011,21,1112,111...\n",
       "126500  1,0,2,0,0,6,0,0,0,21,0,0,0,3,79,0,0,0,0,41,311...\n",
       "217366  1,2,4,8,15,30,58,114,225,443,871,1715,3375,664...\n",
       "4216    1,2,12,432,31104,6718464,8707129344,2256887925...\n",
       "65934   1,2,0,3,0,0,1,4,1,0,2,0,0,2,0,5,0,2,0,0,0,4,2,..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset(data):\n",
    "    \"\"\"\n",
    "    Given dataset with Sequence only, split it into X,y\n",
    "    \"\"\"\n",
    "    #df['numbers'] = df.Sequence.str.split(',').map(np.float128)    \n",
    "    df = data.Sequence.str.rpartition(',').iloc[:, [0, 2]]\n",
    "    df.rename(columns={0: 'sequence', 2: 'ending'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = prep_dataset(df)\n",
    "test_df = prep_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>ending</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180820</th>\n",
       "      <td>1,2,3,6,11,14,29,44,64,65,74,92,106,127,153,16...</td>\n",
       "      <td>2617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220915</th>\n",
       "      <td>1,50798448,190026633752982,1646057381698954570...</td>\n",
       "      <td>52047326332129638504907000521132040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182711</th>\n",
       "      <td>41,27,23,21,141,63,49,301,43,167,89,521,203,67...</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40043</th>\n",
       "      <td>15,20,21,28,35,39,44,48,51,52,55,65,69,85,91,9...</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144094</th>\n",
       "      <td>1,1,5,49,653,10201,174965,3188641,60623645,118...</td>\n",
       "      <td>2110916340429978173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sequence  \\\n",
       "Id                                                          \n",
       "180820  1,2,3,6,11,14,29,44,64,65,74,92,106,127,153,16...   \n",
       "220915  1,50798448,190026633752982,1646057381698954570...   \n",
       "182711  41,27,23,21,141,63,49,301,43,167,89,521,203,67...   \n",
       "40043   15,20,21,28,35,39,44,48,51,52,55,65,69,85,91,9...   \n",
       "144094  1,1,5,49,653,10201,174965,3188641,60623645,118...   \n",
       "\n",
       "                                     ending  \n",
       "Id                                           \n",
       "180820                                 2617  \n",
       "220915  52047326332129638504907000521132040  \n",
       "182711                                  427  \n",
       "40043                                   365  \n",
       "144094                  2110916340429978173  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(data, n, terms):\n",
    "    \"\"\"\n",
    "    Generate random samples from data\n",
    "    \"\"\"\n",
    "    samples = data.sample(n)\n",
    "    X = samples.sequence.map(lambda x: x if x.count(',') < terms else x.split(',', (x.count(',') - (terms - 1)))[-1])\n",
    "    y = samples.ending\n",
    "    return X, y\n",
    "X, y = random_sampling(train_df, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet=' 0123456789,-'\n",
    "n_chars = len(alphabet)\n",
    "n_terms = 10\n",
    "in_length = 200\n",
    "out_length = 20\n",
    "\n",
    "def prep_sampling(data, n_samples, X_maxlen, y_maxlen, alphabet):\n",
    "    \"\"\"\n",
    "    Sample n samples from data, encode them and add padding\n",
    "    \"\"\"\n",
    "    # alphabet should start with padding value\n",
    "    X, y = random_sampling(data, n_samples, terms=n_terms)\n",
    "    X, y = seq_encode(X, y, alphabet)\n",
    "    X = pad_sequences(X, maxlen=X_maxlen, value=0, dtype=np.int16)\n",
    "    y = pad_sequences(y, maxlen=y_maxlen, value=0, dtype=np.int16)\n",
    "    X, y = one_hot_encode(X, y, len(alphabet))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def train_sampling(X_maxlen, y_maxlen, alphabet, batch_size=32):\n",
    "    # alphabet should start with padding value\n",
    "    while True:\n",
    "        X, y = prep_sampling(train_df, batch_size, X_maxlen, y_maxlen, alphabet)\n",
    "        yield np.array(X), np.array(y)\n",
    "\n",
    "def val_sampling(X_maxlen, y_maxlen, alphabet, batch_size=32):\n",
    "    while True:\n",
    "        X, y = prep_sampling(test_df, batch_size, X_maxlen, y_maxlen, alphabet)\n",
    "        yield np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 32)                5888      \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 20, 32)            8320      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 13)            429       \n",
      "=================================================================\n",
      "Total params: 14,637\n",
      "Trainable params: 14,637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Building model now\n",
    "mod = Sequential()\n",
    "mod.add(LSTM(32, input_shape=(in_length, n_chars)))\n",
    "mod.add(RepeatVector(out_length))\n",
    "mod.add(LSTM(32, return_sequences=True))\n",
    "mod.add(TimeDistributed(Dense(n_chars, activation='softmax')))\n",
    "mod.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy', 'mae'])\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "250/250 [==============================] - 33s 132ms/step - loss: 1.0381 - acc: 0.6305 - mean_absolute_error: 0.0615\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 34s 136ms/step - loss: 1.0471 - acc: 0.6289 - mean_absolute_error: 0.0618\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 1.0402 - acc: 0.6288 - mean_absolute_error: 0.0615\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 1.0087 - acc: 0.6416 - mean_absolute_error: 0.0597\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 33s 132ms/step - loss: 1.0293 - acc: 0.6313 - mean_absolute_error: 0.0609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x133a22a58>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit_generator(train_sampling(in_length, out_length, alphabet), epochs=5, steps_per_epoch=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_predictions(model, n_examples):\n",
    "    X, y = prep_sampling(train_df, n_examples, in_length, out_length, alphabet)\n",
    "    res = model.predict(X)\n",
    "    expected = invert(y, alphabet)\n",
    "    predicted = invert(res, alphabet)\n",
    "    for i in range(n_examples):\n",
    "        print(f\"Expected={expected[i]}, Predicted={predicted[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=  135863147487423972, Predicted=  111999111111111110\n",
      "Expected=                 572, Predicted=                 110\n",
      "Expected=        801373175814, Predicted=          6777799999\n",
      "Expected=34406400000000000000, Predicted= 0000000000000000000\n",
      "Expected=                 147, Predicted=                 111\n",
      "Expected=                   1, Predicted=                   0\n",
      "Expected=               14237, Predicted=               11100\n",
      "Expected=                3066, Predicted=                1110\n",
      "Expected=          2326692356, Predicted=          1111111100\n",
      "Expected=                2222, Predicted=                1111\n",
      "Expected=         11730347948, Predicted=         12559911100\n",
      "Expected=           182025792, Predicted=          1111111111\n",
      "Expected=             9426681, Predicted=           100000000\n",
      "Expected=                 841, Predicted=                 111\n",
      "Expected=             7258701, Predicted=            11111111\n",
      "Expected=               12121, Predicted=               11111\n",
      "Expected=             3888823, Predicted=             1379999\n",
      "Expected=                1465, Predicted=                1111\n",
      "Expected=             2674855, Predicted=             1111111\n",
      "Expected=           116366274, Predicted=           111100000\n"
     ]
    }
   ],
   "source": [
    "compare_predictions(mod, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(model, data):\n",
    "    \"\"\"\n",
    "    Compute accuracy score for the given dataset\n",
    "    \"\"\"\n",
    "    X, y = prep_sampling(data, data.shape[0], in_length, out_length, alphabet)\n",
    "    res = model.predict(X)\n",
    "    cnt_correct = (res == y).sum()\n",
    "    print(f\"Accuracy score: {cnt_correct/res.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_score(mod, train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
